What are the very general goals of this project? (No Implementation Details) 

Make a personal assistant using open source LLMs.
    - The assistant will be given commands.
    - The assistant will take action based on the commands.
    - The assistant will articulate the actions to take and ask for confirmation.
    - The assistant will perform the actions.
    - The assistant will ask questions for clarification during a run.

How will the personal assisant do this?
    - The commands will be given in text via voice or text interface.
    - The specific commands will be inferred from natural language using LLMs.
    - An action plan will be defined
    - The changes will be reported via text and voice to the user
    - The agent will have full control over the server to perform actions
    - There will be an image component that captures the user's screen and sends it to the model
    - There will be an eye tracker that gives context of what the user is focused on to the model
